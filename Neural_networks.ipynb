{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/data_science/gridcomputing/Modified_dataset_20001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3,random_state = 0)\n",
    "Y=np.array(df['WaitTime'])\n",
    "X=df.drop('WaitTime',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14000, 18), (6001, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np.array(train['WaitTime'])\n",
    "train_x=train.drop('WaitTime',axis=1)\n",
    "test_y=np.array(test['WaitTime'])\n",
    "test_x=test.drop('WaitTime',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-10\n",
    "\n",
    "\n",
    "def _error(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Simple error \"\"\"\n",
    "    return actual - predicted\n",
    "\n",
    "\n",
    "def _percentage_error(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"\n",
    "    Percentage error\n",
    "    Note: result is NOT multiplied by 100\n",
    "    \"\"\"\n",
    "    return _error(actual, predicted) / (actual + EPSILON)\n",
    "\n",
    "\n",
    "def _naive_forecasting(actual: np.ndarray, seasonality: int = 1):\n",
    "    \"\"\" Naive forecasting method which just repeats previous samples \"\"\"\n",
    "    return actual[:-seasonality]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs(_error(actual, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smape(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"\n",
    "    Symmetric Mean Absolute Percentage Error\n",
    "    Note: result is NOT multiplied by 100\n",
    "    \"\"\"\n",
    "    return np.mean(2.0 * np.abs(actual - predicted) / ((np.abs(actual) + np.abs(predicted)) + EPSILON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Root Mean Squared Error \"\"\"\n",
    "    return np.sqrt(mse(actual, predicted))\n",
    "\n",
    "def mse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\" Mean Squared Error \"\"\"\n",
    "    return np.mean(np.square(_error(actual, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n",
    "    \"\"\"\n",
    "    Mean Absolute Scaled Error\n",
    "    Baseline (benchmark) is computed with naive forecasting (shifted by @seasonality)\n",
    "    \"\"\"\n",
    "    return mae(actual, predicted) / mae(actual[seasonality:], _naive_forecasting(actual, seasonality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 167,169\n",
      "Trainable params: 167,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train_x.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11200 samples, validate on 2800 samples\n",
      "Epoch 1/15\n",
      "11200/11200 [==============================] - 2s 138us/step - loss: 334358.5568 - mean_absolute_error: 334358.4062 - val_loss: 44622.2669 - val_mean_absolute_error: 44622.2695\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 44622.26692, saving model to Weights-001--44622.26692.hdf5\n",
      "Epoch 2/15\n",
      "11200/11200 [==============================] - 1s 83us/step - loss: 28710.1238 - mean_absolute_error: 28710.1309 - val_loss: 10730.2953 - val_mean_absolute_error: 10730.2988\n",
      "\n",
      "Epoch 00002: val_loss improved from 44622.26692 to 10730.29533, saving model to Weights-002--10730.29533.hdf5\n",
      "Epoch 3/15\n",
      "11200/11200 [==============================] - 1s 71us/step - loss: 15416.3003 - mean_absolute_error: 15416.3057 - val_loss: 8834.0116 - val_mean_absolute_error: 8834.0117\n",
      "\n",
      "Epoch 00003: val_loss improved from 10730.29533 to 8834.01161, saving model to Weights-003--8834.01161.hdf5\n",
      "Epoch 4/15\n",
      "11200/11200 [==============================] - 1s 73us/step - loss: 12097.3050 - mean_absolute_error: 12097.3047 - val_loss: 7845.5712 - val_mean_absolute_error: 7845.5708\n",
      "\n",
      "Epoch 00004: val_loss improved from 8834.01161 to 7845.57124, saving model to Weights-004--7845.57124.hdf5\n",
      "Epoch 5/15\n",
      "11200/11200 [==============================] - 1s 81us/step - loss: 10429.4068 - mean_absolute_error: 10429.4131 - val_loss: 7519.9634 - val_mean_absolute_error: 7519.9619\n",
      "\n",
      "Epoch 00005: val_loss improved from 7845.57124 to 7519.96337, saving model to Weights-005--7519.96337.hdf5\n",
      "Epoch 6/15\n",
      "11200/11200 [==============================] - 1s 87us/step - loss: 10435.0784 - mean_absolute_error: 10435.0781 - val_loss: 6849.8978 - val_mean_absolute_error: 6849.8979\n",
      "\n",
      "Epoch 00006: val_loss improved from 7519.96337 to 6849.89777, saving model to Weights-006--6849.89777.hdf5\n",
      "Epoch 7/15\n",
      "11200/11200 [==============================] - 1s 72us/step - loss: 8775.6554 - mean_absolute_error: 8775.6533 - val_loss: 6664.2551 - val_mean_absolute_error: 6664.2559\n",
      "\n",
      "Epoch 00007: val_loss improved from 6849.89777 to 6664.25513, saving model to Weights-007--6664.25513.hdf5\n",
      "Epoch 8/15\n",
      "11200/11200 [==============================] - 1s 78us/step - loss: 8684.7080 - mean_absolute_error: 8684.7070 - val_loss: 6638.1501 - val_mean_absolute_error: 6638.1509\n",
      "\n",
      "Epoch 00008: val_loss improved from 6664.25513 to 6638.15012, saving model to Weights-008--6638.15012.hdf5\n",
      "Epoch 9/15\n",
      "11200/11200 [==============================] - 1s 81us/step - loss: 8639.6350 - mean_absolute_error: 8639.6348 - val_loss: 6635.0271 - val_mean_absolute_error: 6635.0264\n",
      "\n",
      "Epoch 00009: val_loss improved from 6638.15012 to 6635.02709, saving model to Weights-009--6635.02709.hdf5\n",
      "Epoch 10/15\n",
      "11200/11200 [==============================] - 1s 74us/step - loss: 8639.3047 - mean_absolute_error: 8639.3047 - val_loss: 6635.0258 - val_mean_absolute_error: 6635.0249\n",
      "\n",
      "Epoch 00010: val_loss improved from 6635.02709 to 6635.02579, saving model to Weights-010--6635.02579.hdf5\n",
      "Epoch 11/15\n",
      "11200/11200 [==============================] - 1s 74us/step - loss: 8639.3102 - mean_absolute_error: 8639.3115 - val_loss: 6635.0269 - val_mean_absolute_error: 6635.0264\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6635.02579\n",
      "Epoch 12/15\n",
      "11200/11200 [==============================] - 1s 90us/step - loss: 8639.3124 - mean_absolute_error: 8639.3125 - val_loss: 6635.0243 - val_mean_absolute_error: 6635.0249\n",
      "\n",
      "Epoch 00012: val_loss improved from 6635.02579 to 6635.02432, saving model to Weights-012--6635.02432.hdf5\n",
      "Epoch 13/15\n",
      "11200/11200 [==============================] - 1s 79us/step - loss: 8639.3084 - mean_absolute_error: 8639.3008 - val_loss: 6635.0603 - val_mean_absolute_error: 6635.0601\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 6635.02432\n",
      "Epoch 14/15\n",
      "11200/11200 [==============================] - 1s 73us/step - loss: 8639.3140 - mean_absolute_error: 8639.3164 - val_loss: 6635.0273 - val_mean_absolute_error: 6635.0278\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6635.02432\n",
      "Epoch 15/15\n",
      "11200/11200 [==============================] - 1s 77us/step - loss: 8639.3228 - mean_absolute_error: 8639.3252 - val_loss: 6635.3065 - val_mean_absolute_error: 6635.3071\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6635.02432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25b2198c048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(train_x, train_y, epochs=15, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6836.400984074056"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1610362904647986"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43539.272168651114"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5364978892911283"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mase(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100, 75, 50, 25), learning_rate='adaptive',\n",
       "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=0, shuffle=True, solver='sgd', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(hidden_layer_sizes = (100, 75, 50, 25), activation = 'tanh', solver = 'sgd', learning_rate = 'adaptive',random_state = 0,max_iter=500,warm_start=True)\n",
    "reg.fit(train_x, train_y)\n",
    "\n",
    "#redict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12563.555339801036"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = reg.predict(test_x)\n",
    "mae(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43022.303601787164"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8025440376356203"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9859458123503372"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mase(test_y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
